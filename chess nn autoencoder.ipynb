{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3137b42-073b-4339-9e4b-d73ecb8bca5f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras import callbacks\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import time\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ca6ea5e0-be5d-48c5-a90c-3ba408dfe616",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_INPUT_FILE = 'lichessParser/nnInput.npy'\n",
    "BATCH_SIZE = 4096  # Define the batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c55dbe40-49e2-4d4c-86a4-1f1e4bd357a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numStr(num):\n",
    "    return '{:,}'.format(\n",
    "        np.round(num, 6)\n",
    "    ).replace(',', ' ')\n",
    "\n",
    "def load_data_in_batches(file_path, batch_size):\n",
    "    \"\"\"\n",
    "    Generator function to load large numpy data in batches.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the .npy file containing the neural network input data.\n",
    "        batch_size (int): Size of the batches to load.\n",
    "    \n",
    "    Yields:\n",
    "        Numpy arrays of size (batch_size, feature_length) until the full dataset is processed.\n",
    "    \"\"\"\n",
    "    # Load the memory-mapped file\n",
    "    mmapped_array = np.load(file_path, mmap_mode='r')  # Read in memory-mapped mode\n",
    "    \n",
    "    total_samples = mmapped_array.shape[0]  # Total number of entries (rows)\n",
    "    feature_length = mmapped_array.shape[1]  # Number of features (columns)\n",
    "    print('tot batches:', numStr(total_samples/batch_size), 'tot samples: ', numStr(total_samples))\n",
    "    # Iterate over the file in batches\n",
    "    for start_idx in range(0, total_samples, batch_size):\n",
    "        end_idx = min(start_idx + batch_size, total_samples)\n",
    "        \n",
    "        # Yield the next batch\n",
    "        yield mmapped_array[start_idx:end_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "011b497c-313b-4577-9cee-92561f9bf724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Define and Train the Encoder-Decoder model\n",
    "my_regularizer = regularizers.l1(10e-8)\n",
    "\n",
    "input_layer = Input(shape=(65,))\n",
    "hidden_encoder = Dense(100, activation='tanh')(input_layer)\n",
    "# hidden_encoder2 = Dense(100, activation='relu')(hidden_encoder)\n",
    "latent_layer = Dense(30,\n",
    "                     activation='tanh', \n",
    "                     activity_regularizer=my_regularizer\n",
    "                    )(hidden_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cdecde10-981a-42b8-869b-e613bc279ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder: Latent space -> Hidden layer -> Output (2 bits)\n",
    "hidden_decoder = Dense(100, activation='relu')(latent_layer)\n",
    "# hidden_decoder2 = Dense(2000, activation='tanh')(hidden_decoder)\n",
    "output_layer = Dense(65, activation='tanh')(hidden_decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "73266aca-ddee-400b-b1a0-46df0c2276e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full model: Encoder + Decoder\n",
    "autoencoder = Model(inputs=input_layer, outputs=output_layer)\n",
    "optimizer = Adam(\n",
    "    learning_rate=0.005\n",
    ")\n",
    "autoencoder.compile(\n",
    "    optimizer=optimizer,\n",
    "   # loss='mse'\n",
    "    loss=keras.losses.MeanAbsoluteError(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "89aefd7c-5a35-4b1c-9cf6-16f8cb992a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== epoch 1 ======\n",
      "tot batches: 2 447.951416 tot samples:  10 026 809\n",
      "250 | 250 ] avg loss: 0.103748\n",
      "500 | 500 ] avg loss: 0.070374\n",
      "750 | 750 ] avg loss: 0.065749\n",
      "1 000 | 1 000 ] avg loss: 0.062957\n",
      "1 250 | 1 250 ] avg loss: 0.061457\n",
      "1 500 | 1 500 ] avg loss: 0.059346\n",
      "1 750 | 1 750 ] avg loss: 0.058086\n",
      "2 000 | 2 000 ] avg loss: 0.057169\n",
      "2 250 | 2 250 ] avg loss: 0.056327\n",
      "===== epoch 2 ======\n",
      "tot batches: 2 447.951416 tot samples:  10 026 809\n",
      "2 500 | 52 ] avg loss: 0.055935\n",
      "2 750 | 302 ] avg loss: 0.055567\n",
      "3 000 | 552 ] avg loss: 0.05542\n",
      "3 250 | 802 ] avg loss: 0.055085\n",
      "3 500 | 1 052 ] avg loss: 0.054572\n",
      "3 750 | 1 302 ] avg loss: 0.054647\n",
      "4 000 | 1 552 ] avg loss: 0.054123\n",
      "4 250 | 1 802 ] avg loss: 0.053762\n",
      "4 500 | 2 052 ] avg loss: 0.053466\n",
      "4 750 | 2 302 ] avg loss: 0.053461\n",
      "===== epoch 3 ======\n",
      "tot batches: 2 447.951416 tot samples:  10 026 809\n",
      "5 000 | 104 ] avg loss: 0.053367\n",
      "5 250 | 354 ] avg loss: 0.053041\n",
      "5 500 | 604 ] avg loss: 0.052992\n",
      "5 750 | 854 ] avg loss: 0.052976\n",
      "6 000 | 1 104 ] avg loss: 0.05272\n",
      "6 250 | 1 354 ] avg loss: 0.052697\n",
      "6 500 | 1 604 ] avg loss: 0.052807\n",
      "6 750 | 1 854 ] avg loss: 0.052545\n",
      "7 000 | 2 104 ] avg loss: 0.052461\n",
      "7 250 | 2 354 ] avg loss: 0.052485\n",
      "===== epoch 4 ======\n",
      "tot batches: 2 447.951416 tot samples:  10 026 809\n",
      "7 500 | 156 ] avg loss: 0.052293\n",
      "7 750 | 406 ] avg loss: 0.0516\n",
      "8 000 | 656 ] avg loss: 0.05145\n",
      "8 250 | 906 ] avg loss: 0.051815\n",
      "8 500 | 1 156 ] avg loss: 0.051348\n",
      "8 750 | 1 406 ] avg loss: 0.051307\n",
      "9 000 | 1 656 ] avg loss: 0.051499\n",
      "9 250 | 1 906 ] avg loss: 0.05122\n",
      "9 500 | 2 156 ] avg loss: 0.051267\n",
      "9 750 | 2 406 ] avg loss: 0.051095\n",
      "===== epoch 5 ======\n",
      "tot batches: 2 447.951416 tot samples:  10 026 809\n",
      "10 000 | 208 ] avg loss: 0.051277\n",
      "10 250 | 458 ] avg loss: 0.050773\n",
      "10 500 | 708 ] avg loss: 0.05089\n",
      "10 750 | 958 ] avg loss: 0.050913\n",
      "11 000 | 1 208 ] avg loss: 0.050851\n",
      "11 250 | 1 458 ] avg loss: 0.050463\n",
      "11 500 | 1 708 ] avg loss: 0.051012\n",
      "11 750 | 1 958 ] avg loss: 0.050704\n",
      "12 000 | 2 208 ] avg loss: 0.050791\n",
      "===== epoch 6 ======\n",
      "tot batches: 2 447.951416 tot samples:  10 026 809\n",
      "12 250 | 10 ] avg loss: 0.050677\n",
      "12 500 | 260 ] avg loss: 0.050821\n",
      "12 750 | 510 ] avg loss: 0.050578\n",
      "13 000 | 760 ] avg loss: 0.05053\n",
      "13 250 | 1 010 ] avg loss: 0.050569\n",
      "13 500 | 1 260 ] avg loss: 0.050519\n",
      "13 750 | 1 510 ] avg loss: 0.050357\n",
      "14 000 | 1 760 ] avg loss: 0.050465\n",
      "14 250 | 2 010 ] avg loss: 0.050428\n",
      "14 500 | 2 260 ] avg loss: 0.050498\n",
      "===== epoch 7 ======\n",
      "tot batches: 2 447.951416 tot samples:  10 026 809\n",
      "14 750 | 62 ] avg loss: 0.050489\n",
      "15 000 | 312 ] avg loss: 0.0505\n",
      "15 250 | 562 ] avg loss: 0.050444\n",
      "15 500 | 812 ] avg loss: 0.05039\n",
      "15 750 | 1 062 ] avg loss: 0.05039\n",
      "16 000 | 1 312 ] avg loss: 0.050341\n",
      "16 250 | 1 562 ] avg loss: 0.050222\n",
      "16 500 | 1 812 ] avg loss: 0.050409\n",
      "16 750 | 2 062 ] avg loss: 0.05019\n",
      "17 000 | 2 312 ] avg loss: 0.050272\n",
      "===== epoch 8 ======\n",
      "tot batches: 2 447.951416 tot samples:  10 026 809\n",
      "17 250 | 114 ] avg loss: 0.050452\n",
      "17 500 | 364 ] avg loss: 0.050225\n",
      "17 750 | 614 ] avg loss: 0.050323\n",
      "18 000 | 864 ] avg loss: 0.05033\n",
      "18 250 | 1 114 ] avg loss: 0.050201\n",
      "18 500 | 1 364 ] avg loss: 0.050182\n",
      "18 750 | 1 614 ] avg loss: 0.050139\n",
      "19 000 | 1 864 ] avg loss: 0.050121\n",
      "19 250 | 2 114 ] avg loss: 0.050174\n",
      "19 500 | 2 364 ] avg loss: 0.050251\n",
      "===== epoch 9 ======\n",
      "tot batches: 2 447.951416 tot samples:  10 026 809\n",
      "19 750 | 166 ] avg loss: 0.050398\n",
      "20 000 | 416 ] avg loss: 0.049884\n",
      "20 250 | 666 ] avg loss: 0.050079\n",
      "20 500 | 916 ] avg loss: 0.050318\n",
      "20 750 | 1 166 ] avg loss: 0.049936\n",
      "21 000 | 1 416 ] avg loss: 0.049915\n",
      "21 250 | 1 666 ] avg loss: 0.050265\n",
      "21 500 | 1 916 ] avg loss: 0.049987\n",
      "21 750 | 2 166 ] avg loss: 0.050205\n",
      "22 000 | 2 416 ] avg loss: 0.049948\n",
      "===== epoch 10 ======\n",
      "tot batches: 2 447.951416 tot samples:  10 026 809\n",
      "22 250 | 218 ] avg loss: 0.050217\n",
      "22 500 | 468 ] avg loss: 0.049955\n",
      "22 750 | 718 ] avg loss: 0.049946\n",
      "23 000 | 968 ] avg loss: 0.049935\n",
      "23 250 | 1 218 ] avg loss: 0.04991\n",
      "23 500 | 1 468 ] avg loss: 0.049759\n",
      "23 750 | 1 718 ] avg loss: 0.050062\n",
      "24 000 | 1 968 ] avg loss: 0.049779\n",
      "24 250 | 2 218 ] avg loss: 0.050137\n",
      "===== epoch 11 ======\n",
      "tot batches: 2 447.951416 tot samples:  10 026 809\n",
      "24 500 | 20 ] avg loss: 0.049838\n",
      "24 750 | 270 ] avg loss: 0.050076\n",
      "25 000 | 520 ] avg loss: 0.049849\n",
      "25 250 | 770 ] avg loss: 0.049919\n",
      "25 500 | 1 020 ] avg loss: 0.049827\n",
      "25 750 | 1 270 ] avg loss: 0.049714\n",
      "26 000 | 1 520 ] avg loss: 0.049576\n",
      "26 250 | 1 770 ] avg loss: 0.049934\n",
      "26 500 | 2 020 ] avg loss: 0.049692\n",
      "26 750 | 2 270 ] avg loss: 0.049689\n",
      "===== epoch 12 ======\n",
      "tot batches: 2 447.951416 tot samples:  10 026 809\n",
      "27 000 | 72 ] avg loss: 0.050012\n",
      "27 250 | 322 ] avg loss: 0.049811\n",
      "27 500 | 572 ] avg loss: 0.049816\n",
      "27 750 | 822 ] avg loss: 0.049724\n",
      "28 000 | 1 072 ] avg loss: 0.049692\n",
      "28 250 | 1 322 ] avg loss: 0.049709\n",
      "28 500 | 1 572 ] avg loss: 0.049675\n",
      "28 750 | 1 822 ] avg loss: 0.049708\n",
      "29 000 | 2 072 ] avg loss: 0.049774\n",
      "29 250 | 2 322 ] avg loss: 0.049668\n",
      "===== epoch 13 ======\n",
      "tot batches: 2 447.951416 tot samples:  10 026 809\n",
      "29 500 | 124 ] avg loss: 0.049773\n",
      "29 750 | 374 ] avg loss: 0.04958\n",
      "30 000 | 624 ] avg loss: 0.049747\n",
      "30 250 | 874 ] avg loss: 0.049646\n",
      "30 500 | 1 124 ] avg loss: 0.049501\n",
      "30 750 | 1 374 ] avg loss: 0.04949\n",
      "31 000 | 1 624 ] avg loss: 0.049776\n",
      "31 250 | 1 874 ] avg loss: 0.049585\n",
      "31 500 | 2 124 ] avg loss: 0.049701\n",
      "31 750 | 2 374 ] avg loss: 0.049514\n",
      "===== epoch 14 ======\n",
      "tot batches: 2 447.951416 tot samples:  10 026 809\n",
      "32 000 | 176 ] avg loss: 0.049861\n",
      "32 250 | 426 ] avg loss: 0.049392\n",
      "32 500 | 676 ] avg loss: 0.049601\n",
      "32 750 | 926 ] avg loss: 0.04975\n",
      "33 000 | 1 176 ] avg loss: 0.049303\n",
      "33 250 | 1 426 ] avg loss: 0.049455\n",
      "33 500 | 1 676 ] avg loss: 0.049733\n",
      "33 750 | 1 926 ] avg loss: 0.049535\n",
      "34 000 | 2 176 ] avg loss: 0.0497\n",
      "34 250 | 2 426 ] avg loss: 0.049585\n",
      "===== epoch 15 ======\n",
      "tot batches: 2 447.951416 tot samples:  10 026 809\n",
      "34 500 | 228 ] avg loss: 0.049816\n",
      "34 750 | 478 ] avg loss: 0.049519\n",
      "35 000 | 728 ] avg loss: 0.049517\n",
      "35 250 | 978 ] avg loss: 0.049618\n",
      "35 500 | 1 228 ] avg loss: 0.04955\n",
      "35 750 | 1 478 ] avg loss: 0.049275\n",
      "36 000 | 1 728 ] avg loss: 0.049601\n",
      "36 250 | 1 978 ] avg loss: 0.04956\n",
      "36 500 | 2 228 ] avg loss: 0.049567\n",
      "===== epoch 16 ======\n",
      "tot batches: 2 447.951416 tot samples:  10 026 809\n",
      "36 750 | 30 ] avg loss: 0.049454\n",
      "37 000 | 280 ] avg loss: 0.049551\n",
      "37 250 | 530 ] avg loss: 0.049449\n",
      "37 500 | 780 ] avg loss: 0.049498\n",
      "37 750 | 1 030 ] avg loss: 0.049389\n",
      "38 000 | 1 280 ] avg loss: 0.049471\n",
      "38 250 | 1 530 ] avg loss: 0.049481\n",
      "38 500 | 1 780 ] avg loss: 0.049504\n",
      "38 750 | 2 030 ] avg loss: 0.049574\n",
      "39 000 | 2 280 ] avg loss: 0.049393\n",
      "===== epoch 17 ======\n",
      "tot batches: 2 447.951416 tot samples:  10 026 809\n",
      "39 250 | 82 ] avg loss: 0.049437\n",
      "39 500 | 332 ] avg loss: 0.049536\n",
      "39 750 | 582 ] avg loss: 0.049402\n",
      "40 000 | 832 ] avg loss: 0.049567\n",
      "40 250 | 1 082 ] avg loss: 0.049213\n",
      "40 500 | 1 332 ] avg loss: 0.049419\n",
      "40 750 | 1 582 ] avg loss: 0.049445\n",
      "41 000 | 1 832 ] avg loss: 0.04937\n",
      "41 250 | 2 082 ] avg loss: 0.049424\n",
      "41 500 | 2 332 ] avg loss: 0.049344\n",
      "===== epoch 18 ======\n",
      "tot batches: 2 447.951416 tot samples:  10 026 809\n",
      "41 750 | 134 ] avg loss: 0.049472\n",
      "42 000 | 384 ] avg loss: 0.049328\n",
      "42 250 | 634 ] avg loss: 0.049331\n",
      "42 500 | 884 ] avg loss: 0.049464\n",
      "42 750 | 1 134 ] avg loss: 0.049155\n",
      "43 000 | 1 384 ] avg loss: 0.049312\n",
      "43 250 | 1 634 ] avg loss: 0.049441\n",
      "43 500 | 1 884 ] avg loss: 0.049232\n",
      "43 750 | 2 134 ] avg loss: 0.049492\n",
      "44 000 | 2 384 ] avg loss: 0.049237\n",
      "===== epoch 19 ======\n",
      "tot batches: 2 447.951416 tot samples:  10 026 809\n",
      "44 250 | 186 ] avg loss: 0.049578\n",
      "44 500 | 436 ] avg loss: 0.049245\n",
      "44 750 | 686 ] avg loss: 0.049138\n",
      "45 000 | 936 ] avg loss: 0.049451\n",
      "45 250 | 1 186 ] avg loss: 0.049201\n",
      "45 500 | 1 436 ] avg loss: 0.049271\n",
      "45 750 | 1 686 ] avg loss: 0.049393\n",
      "46 000 | 1 936 ] avg loss: 0.049195\n",
      "46 250 | 2 186 ] avg loss: 0.049555\n",
      "46 500 | 2 436 ] avg loss: 0.049316\n",
      "===== epoch 20 ======\n",
      "tot batches: 2 447.951416 tot samples:  10 026 809\n",
      "46 750 | 238 ] avg loss: 0.049455\n",
      "47 000 | 488 ] avg loss: 0.049228\n",
      "47 250 | 738 ] avg loss: 0.04925\n",
      "47 500 | 988 ] avg loss: 0.049434\n",
      "47 750 | 1 238 ] avg loss: 0.049229\n",
      "48 000 | 1 488 ] avg loss: 0.049024\n",
      "48 250 | 1 738 ] avg loss: 0.04946\n",
      "48 500 | 1 988 ] avg loss: 0.049176\n",
      "48 750 | 2 238 ] avg loss: 0.049415\n",
      "=========== D O N E ================\n"
     ]
    }
   ],
   "source": [
    "ittr = 0\n",
    "totLoss = 0\n",
    "print_every = 250\n",
    "\n",
    "for i in range(0, 20):\n",
    "    batch_num = 0\n",
    "    print('===== epoch', i+1, '======')\n",
    "    for batch in load_data_in_batches(DATA_INPUT_FILE, BATCH_SIZE):\n",
    "        # Example of feeding batch to a neural network (TensorFlow or PyTorch)\n",
    "        # model.train_on_batch(batch)  # TensorFlow/Keras training example\n",
    "        # OR\n",
    "        # output = model(batch)        # PyTorch training example\n",
    "\n",
    "        # You can also perform any data manipulation or processing here\n",
    "        # autoencoder.fit(input_data, output_data, epochs=100, verbose=0)\n",
    "        output_data = batch.copy()\n",
    "        loss = autoencoder.train_on_batch(x=batch, y=output_data)\n",
    "        totLoss = totLoss + loss\n",
    "\n",
    "        if ittr % print_every == 0 and not ittr == 0:\n",
    "            print(\n",
    "                numStr(ittr)+' | '+numStr(batch_num),\n",
    "                '] avg loss:',\n",
    "                numStr(totLoss/print_every)\n",
    "            )\n",
    "            totLoss = 0\n",
    "\n",
    "        ittr = ittr+1\n",
    "        batch_num = batch_num+1\n",
    "\n",
    "print('=========== D O N E ================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "92724506-1082-476a-9e9c-a022d62d8599",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Maybe you meant '==' or ':=' instead of '='? (328716366.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[53], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    batch=4096, LR=0.005,  loss: 0.067, epochs: 19  (reached 0.067 at epoch 9)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax. Maybe you meant '==' or ':=' instead of '='?\n"
     ]
    }
   ],
   "source": [
    "# struct: 65 -> 1000 -> 100 -> 30 -> 100 -> 1000 -> 65 (with regulizer), relu\n",
    "batch=4096, LR=0.005,  loss: 0.058 , epochs: 33  (reached 0.058 at epoch 20)\n",
    "\n",
    "# struct: 65 -> 300 -> 100 -> 30 -> 100 -> 300 -> 65 (with regulizer), relu\n",
    "batch=4096, LR=0.005,  loss: 0.045, epochs: 20  (reached 0.045 at epoch 11)\n",
    "\n",
    "# struct: 65 -> 2000 -> 30 -> 2000 -> 65 (with regulizer), relu\n",
    "batch=1024, LR=0.0003, loss: 0.025\n",
    "batch=256,  LR=0.0003, loss: 0.025, epochs: 6 (reached 0.025 at epoch 5)\n",
    "batch=4096, LR=0.0003, loss: 0.031, epochs: 30 (still decreasing)\n",
    "batch=4096, LR=0.005,  loss: 0.025, epochs: 20  (reached 0.025 at epoch 9)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15df21d-c17a-4be6-a601-aab7860d8b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = autoencoder.predict(input_data)\n",
    "# print(predictions)\n",
    "# for i, input_example in enumerate(input_data):\n",
    "#     print(f\"Input: {input_example}, Predicted output: {np.round(predictions[i])}\")\n",
    "    \n",
    "for batch in load_data_in_batches(DATA_INPUT_FILE, 15):\n",
    "    for i, nnInput in enumerate(batch):\n",
    "        print(np.array([nnInput]))\n",
    "        output = autoencoder.predict(np.array([nnInput]))\n",
    "        # print(output)\n",
    "        print('===============')\n",
    "        print('====== set',i)\n",
    "        for j, predicted in enumerate(output[0]):\n",
    "            print(\n",
    "                'ans',nnInput[j],\n",
    "                'got', np.round(predicted, 3),\n",
    "                'err', np.round(abs(nnInput[j]-predicted), 4)\n",
    "            )\n",
    "\n",
    "    break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "71ff0a42-1d61-4ec9-869d-fa7ad7a67ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE THE MODEL\n",
    "autoencoder.save('chess_autoencoder.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d50636-f70b-4e26-8ad0-8aea59b8b576",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.predict(np.array([[-1., -0.667, 0., -0.5, -0.833, -1., -0.5, -0.333, -0.667, -0.167\n",
    ", -0.167, 0., 0., -0.167, -0.167, -0.167, -0.167, 0., 0., -0.333\n",
    ", 0., 0., 0., 0., 0., 0., 0., 0., -0.167, 0.\n",
    ", 0., 0., 0., 0., 0., 0., 0.167, 0., 0.167, 0.\n",
    ", 0., 0., 0., 0.167, 0., 0., 0., 0., 0., 0.167\n",
    ", 0.167, 0., 0., 0., 0., 0.167, 0.167, 0.667, 0.333, 0.5\n",
    ", 0.833, 1., 0.5, 0.333, 0.667]]))\n",
    "\n",
    "encoder = Model(inputs=input_layer, outputs=latent_layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38134315-2445-42e8-8ee5-c9bbce140d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_input = Input(shape=(1,))\n",
    "decoder_hidden = autoencoder.layers[-3](latent_input)  # The hidden decoder layer\n",
    "decoder_hidden2 = autoencoder.layers[-2](decoder_hidden)  # The hidden decoder layer\n",
    "decoder_output = autoencoder.layers[-1](decoder_hidden2)  # The output decoder layer\n",
    "decoder = Model(inputs=latent_input, outputs=decoder_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d89b7ed-ff32-44e3-8615-16849b1c24aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Input -> Latent Space -> Reconstructed Output\")\n",
    "for i, input_example in enumerate(input_data):\n",
    "    # Get latent space value\n",
    "    latent_values = encoder.predict(np.array([input_example]))\n",
    "    \n",
    "    # Get reconstructed output\n",
    "    reconstructed_output = decoder.predict(latent_values)\n",
    "    \n",
    "    # Print the result\n",
    "    print(f\"Input: {input_example}, Latent Space: {latent_values[0]}, Reconstructed Output: {np.round(reconstructed_output[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2471a515-1ecf-40b5-bff8-397adb1d5031",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_slider1 = widgets.FloatSlider(value=0.0, min=-1, max=1, step=0.004, description='Latent 1', layout=widgets.Layout(width='800px'))\n",
    "#latent_slider2 = widgets.FloatSlider(value=0.0, min=-2.0, max=2.0, step=0.01, description='Latent 2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5785aa3f-3111-47a4-bcbf-3fed7dee9bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_display = widgets.Output()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1909dfec-75d7-4c6f-b718-f76bad8c68ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_output(change=None):\n",
    "    #latent_values = np.array([[latent_slider1.value, latent_slider2.value]])\n",
    "    latent_values = np.array([[latent_slider1.value]])\n",
    "    predicted_output = decoder.predict(latent_values)\n",
    "    with output_display:\n",
    "        output_display.clear_output(wait=True)\n",
    "        print(f\"Latent space: {latent_values}\")\n",
    "        print(f\"Decoded output: {np.round(predicted_output, 2)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4478345d-0d24-4706-8d93-3dd6ed036301",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_slider1.observe(update_output, names='value')\n",
    "#latent_slider2.observe(update_output, names='value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c23686-9e53-4f7d-a9ed-e804b517de06",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(latent_slider1, output_display)\n",
    "#display(latent_slider1, latent_slider2, output_display)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e9210d-82c7-41ac-b352-ee1d9aace047",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_output()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be0f956-a72b-4444-8628-d926dcf915c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa71867-f97c-493f-b165-d0e1157e90fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a84477e-2a81-4006-bc8a-6198c1b7950a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
